{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decentralized Multi-Agent Pathfinding: A Game-Theoretic Approach\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In contrast to **centralized** planners which possess a global \"god's-eye view\" to compute optimal plans for all agents simultaneously, **decentralized** approaches grant autonomy to individual agents. Each agent plans for itself and coordinates with others to resolve conflicts. This paradigm models agents as rational actors who are myopic (planning for themselves) but socially compliant (obeying a set of coordination rules).\n",
    "\n",
    "We can frame this coordination challenge as a cooperative game. The algorithm we will model is **Prioritized Planning**, where agents follow a strict social hierarchy to negotiate who gets the right-of-way.\n",
    "\n",
    "***\n",
    "\n",
    "### The Base Game: Prioritized Planning in an Open Environment\n",
    "\n",
    "We first consider the base case where the only obstacles are the other agents.\n",
    "\n",
    "#### Game Formulation (Base Case)\n",
    "\n",
    "This is a **fully cooperative game** where all players win or lose as a team.\n",
    "\n",
    "* **Players**: A set of $k$ agents, $\\mathcal{A} = \\{A_1, A_2, \\dots, A_k\\}$.\n",
    "* **Environment**: A graph $G=(V, E)$ representing the grid.\n",
    "* **Objective**: To find a set of conflict-free paths, $\\Pi = \\{\\pi_1, \\pi_2, \\dots, \\pi_k\\}$, that brings every agent from its start location $s_i$ to its goal location $g_i$. The team's score is the **sum-of-costs**, which we want to minimize.\n",
    "    \\begin{aligned}\n",
    "    \\text{Cost}(\\Pi) = \\sum_{i=1}^{k} |\\pi_i|\n",
    "    \\end{aligned}\n",
    "    where $|\\pi_i|$ is the length (cost) of the path for agent $A_i$.\n",
    "\n",
    "* **Agent Capability**: Each agent $A_i$ is equipped with a single-agent pathfinding algorithm (e.g., A*) capable of finding an optimal path for itself given a set of dynamic space-time constraints $\\mathcal{C}$.\n",
    "\n",
    "#### The Rules of Play (The Algorithm)\n",
    "\n",
    "The game proceeds sequentially according to a pre-defined \"social rule\" of priority.\n",
    "\n",
    "1.  **Establish Priority**: A strict, total ordering is defined over the agents before planning begins. This priority ranking is fixed.\n",
    "    \\begin{aligned}\n",
    "    A_1 > A_2 > \\dots > A_k\n",
    "    \\end{aligned}\n",
    "\n",
    "2.  **Sequential Pathfinding**: The agents plan one-by-one, from highest to lowest priority.\n",
    "    -   The highest-priority agent, $A_1$, plans its path $\\pi_1$ in a completely empty environment. Its dynamic constraint set, $\\mathcal{C}_0$, is empty.\n",
    "        \\begin{aligned}\n",
    "        \\pi_1 = \\arg\\min_{\\pi} \\text{cost}(\\pi \\mid \\mathcal{C}_0 = \\emptyset)\n",
    "        \\end{aligned}\n",
    "    -   Every subsequent agent $A_i$ must compute its shortest path while treating the paths of all previously planned agents $\\{A_1, \\dots, A_{i-1}\\}$ as dynamic obstacles defined in the constraint set $\\mathcal{C}_{i-1}$.\n",
    "        \\begin{aligned}\n",
    "        \\pi_i = \\arg\\min_{\\pi} \\text{cost}(\\pi \\mid \\mathcal{C}_{i-1})\n",
    "        \\end{aligned}\n",
    "    -   After finding its path $\\pi_i$, the locations it occupies are added to the constraint set for all agents that follow. The new constraint set $\\mathcal{C}_i$ becomes:\n",
    "        \\begin{aligned}\n",
    "        \\mathcal{C}_i = \\mathcal{C}_{i-1} \\cup \\{ (\\pi_i(t), t) \\mid t \\in [0, \\infty) \\}\n",
    "        \\end{aligned}\n",
    "\n",
    "#### Analysis of the Base Game\n",
    "This decentralized \"game\" is a powerful heuristic, but it comes with significant trade-offs:\n",
    "* **Optimality**: It is **not optimal**. A high-priority agent's selfish choice may lead to a poor overall team score.\n",
    "* **Completeness**: It is **not complete**. A high-priority agent can block a low-priority agent in a way that makes a solution impossible to find, even if one exists.\n",
    "* **Complexity**: Its primary advantage is speed. The time complexity is polynomial in the number of agents, roughly $k \\times \\text{Cost(A*)}$, which is highly scalable.\n",
    "\n",
    "***\n",
    "\n",
    "### Extension: Incorporating Static Obstacles\n",
    "\n",
    "Now, let's see how the theory adapts when we add a permanent, static obstacle to the environment.\n",
    "\n",
    "#### The Conceptual Change\n",
    "\n",
    "Adding a static obstacle does not change the high-level, turn-based logic of Prioritized Planning. The agents still plan sequentially according to their priority. The change occurs at the **low level**: the single-agent pathfinding problem becomes more difficult.\n",
    "\n",
    "Each agent's individual A* search must now avoid two types of constraints simultaneously:\n",
    "1.  The **dynamic constraints** $\\mathcal{C}$ from higher-priority agents' paths.\n",
    "2.  A new set of **static constraints** $\\mathcal{O}$ representing the obstacle.\n",
    "\n",
    "#### Formalizing the Change\n",
    "\n",
    "We introduce a set $\\mathcal{O} \\subset V$ containing all locations `(row, col)` that are permanently blocked by the obstacle.\n",
    "\n",
    "The pathfinding problem for each agent $A_i$ is modified to include this new constraint set. The agent must find the path with the minimum cost that respects *both* sets.\n",
    "\n",
    "The updated objective for agent $A_i$ is:\n",
    "\\begin{aligned}\n",
    "\\pi_i = \\arg\\min_{\\pi} \\text{cost}(\\pi \\mid \\mathcal{C}_{i-1}, \\mathcal{O})\n",
    "\\end{aligned}\n",
    "\n",
    "This means that during its A* search, an agent must prune any potential move that would land it in a location $v$ where $v \\in \\mathcal{O}$.\n",
    "\n",
    "#### Impact on Performance: Analyzing Your Benchmark Results\n",
    "\n",
    "Your benchmark data perfectly demonstrates the effect of adding the static obstacle set $\\mathcal{O}$.\n",
    "\n",
    "| Metric | No Obstacle | With Obstacle | Change |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Solution Cost** | 38 | 41 | +3 |\n",
    "| **Execution Time**| 0.0044 s | 0.0113 s| +157% |\n",
    "| **States Processed**| 40 | 159 | +298% |\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "1.  **Why did Solution Cost increase?** The obstacle set $\\mathcal{O}$ made the original, optimal paths invalid. It constrained the search space, forcing one or both agents to find a longer detour. This directly increased the total path cost from 38 to 41.\n",
    "\n",
    "2.  **Why did Execution Time and States Processed increase?** The obstacle blocked the \"greedy\" or most direct route for the A\\* planner. Instead of moving in a nearly straight line to the goal, the planner hit the obstacle and had to backtrack and explore many more alternative nodes to find a way around. This increase in exploration is precisely measured by the **298% jump in \"States Processed,\"** which in turn caused the **157% increase in execution time**. The algorithm had to do significantly more work to solve a harder problem."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
